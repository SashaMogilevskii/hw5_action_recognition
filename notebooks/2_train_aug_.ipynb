{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт либ\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from box import Box\n",
    "from tqdm import tqdm\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.io import read_video\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name_video</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>videos/video_0000.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>videos/video_0001.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>videos/video_0002.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>videos/video_0003.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>videos/video_0004.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             name_video        label\n",
       "0           0  videos/video_0000.mp4  tap dancing\n",
       "1           1  videos/video_0001.mp4  tap dancing\n",
       "2           2  videos/video_0002.mp4  tap dancing\n",
       "3           3  videos/video_0003.mp4  tap dancing\n",
       "4           4  videos/video_0004.mp4  tap dancing"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на обновленную нашу дату \n",
    "df = pd.read_csv(\"../data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name_video</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>videos/video_0000.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>videos/video_0001.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>videos/video_0002.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>videos/video_0003.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>videos/video_0004.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             name_video        label  target\n",
       "0           0  videos/video_0000.mp4  tap dancing       0\n",
       "1           1  videos/video_0001.mp4  tap dancing       0\n",
       "2           2  videos/video_0002.mp4  tap dancing       0\n",
       "3           3  videos/video_0003.mp4  tap dancing       0\n",
       "4           4  videos/video_0004.mp4  tap dancing       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Закодируем лейблы в числовые значения \n",
    "unique_labels = df['label'].unique()\n",
    "label_dict = {label: index for index, label in enumerate(unique_labels)}\n",
    "df['target'] = df.label.map(label_dict)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cоздадим конфиг для обучения модели\n",
    "config = Box()\n",
    "\n",
    "config.num_workers = 1\n",
    "config.batch_size = 24\n",
    "config.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config.seed = 1771\n",
    "config.model_name = 'mc3_18'\n",
    "config.num_features = df.target.nunique()\n",
    "config.optimizer_lr = 0.0001\n",
    "config.epochs = 15\n",
    "config.test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidaug import augmentors as va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем датаcэт для наших данных \n",
    "\n",
    "class DanceDanceDataset(Dataset):\n",
    "    def __init__(self, df, is_train = False):\n",
    "        self.df = df\n",
    "        self.video_path = \"..\"\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        sometimes = lambda aug: va.Sometimes(0.5, aug)\n",
    "        self.aug = va.Sequential([ \n",
    "            va.RandomRotate(degrees=(-40, 40)),  \n",
    "            sometimes(va.HorizontalFlip())])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        target = row['target']\n",
    "        \n",
    "        video_path = os.path.join(self.video_path, row['name_video'])\n",
    "\n",
    "        video, audio, info = read_video(video_path, pts_unit=\"sec\")\n",
    "        # Беру только 16 кадров. \n",
    "        if len(video) > 0:\n",
    "            if len(video) < 48:\n",
    "                video = video[:16] \n",
    "            else:\n",
    "                video = video[:48:3]\n",
    "            if self.is_train:\n",
    "                video = video.numpy()\n",
    "                video = self.aug(video)\n",
    "                video = torch.Tensor(video)\n",
    "            resize_transform = transforms.Resize((112, 112))\n",
    "            video_resized = torch.stack([resize_transform(frame.permute(2, 0, 1)).permute(1, 2, 0) for frame in video])\n",
    "            video_normalized = video_resized.permute(3, 0, 1, 2) \n",
    "\n",
    "            # Лениво нормализую \n",
    "            tensor_3d = video_normalized / 255 \n",
    "        else:\n",
    "            tensor_3d = torch.empty(3, 16, 112, 112)\n",
    "            \n",
    "        label = torch.tensor(target).long()\n",
    "        return tensor_3d, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16, 112, 112])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = DanceDanceDataset(df.reset_index())\n",
    "dataset_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем наши данные на тест и трейн. cоздадим тренеровочный и тестовый датасэт и даталоадэры\n",
    "train_df, val_df = train_test_split(df, \n",
    "                                    test_size=config.test_size,\n",
    "                                    random_state=config.seed,\n",
    "                                    stratify=df['target']\n",
    "                                   )\n",
    "dataset_train = DanceDanceDataset(train_df.reset_index(),\n",
    "                                 is_train=True)\n",
    "dataset_test = DanceDanceDataset(val_df.reset_index(),\n",
    "                                is_train=True)\n",
    "\n",
    "train_loader = DataLoader(dataset_train,\n",
    "                          batch_size=config.batch_size,\n",
    "                          shuffle=True,\n",
    "                          \n",
    "#                          num_workers=config.num_workers\n",
    "                         )\n",
    "valid_loader = DataLoader(dataset_test,\n",
    "                          batch_size=config.batch_size,\n",
    "#                          num_workers=config.num_workers\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/vision/main/models/generated/torchvision.models.video.mc3_18.html#mc3-18\n",
    "\n",
    "# Загрузка предобученной модели mc3_18\n",
    "model = models.video.mc3_18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, config.num_features)\n",
    "model.to(config.device)\n",
    "config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.optimizer_lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------epoch:1/15---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [20:29<00:00, 15.18s/it, gpu_load=5.11GB, loss=1.8898]\n",
      "Testing: 100%|██████████| 21/21 [05:17<00:00, 15.13s/it, loss=2.3007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, lr_rate 0.0001\n",
      "loss_train: 2.2010| loss_valid: 2.5516|\n",
      "metric 0.187243\n",
      "Elapsed time: 00:25:46\n",
      "---------------------epoch:2/15---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [24:23<00:00, 18.06s/it, gpu_load=5.11GB, loss=1.4512]\n",
      "Testing: 100%|██████████| 21/21 [06:05<00:00, 17.42s/it, loss=1.7682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, lr_rate 0.0001\n",
      "loss_train: 1.5603| loss_valid: 1.7368|\n",
      "metric 0.465021\n",
      "Elapsed time: 00:30:29\n",
      "---------------------epoch:3/15---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [21:05<00:00, 15.62s/it, gpu_load=5.11GB, loss=1.2966]\n",
      "Testing: 100%|██████████| 21/21 [05:02<00:00, 14.42s/it, loss=1.3867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, lr_rate 0.0001\n",
      "loss_train: 1.2546| loss_valid: 1.6500|\n",
      "metric 0.49177\n",
      "Elapsed time: 00:26:08\n",
      "---------------------epoch:4/15---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [20:24<00:00, 15.12s/it, gpu_load=5.11GB, loss=0.7821]\n",
      "Testing: 100%|██████████| 21/21 [05:01<00:00, 14.37s/it, loss=1.0213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, lr_rate 8e-05\n",
      "loss_train: 1.0009| loss_valid: 1.6004|\n",
      "metric 0.493827\n",
      "Elapsed time: 00:25:26\n",
      "---------------------epoch:5/15---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [19:57<00:00, 14.78s/it, gpu_load=5.11GB, loss=0.6574]\n",
      "Testing: 100%|██████████| 21/21 [04:57<00:00, 14.16s/it, loss=0.9469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, lr_rate 8e-05\n",
      "loss_train: 0.8002| loss_valid: 1.6742|\n",
      "metric 0.493827\n",
      "Elapsed time: 00:24:54\n",
      "---------------------epoch:6/15---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [19:52<00:00, 14.72s/it, gpu_load=5.11GB, loss=0.6074]\n",
      "Testing: 100%|██████████| 21/21 [04:57<00:00, 14.17s/it, loss=0.8849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, lr_rate 8e-05\n",
      "loss_train: 0.6512| loss_valid: 1.6644|\n",
      "metric 0.512346\n",
      "Elapsed time: 00:24:49\n",
      "---------------------epoch:7/15---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [19:52<00:00, 14.73s/it, gpu_load=5.11GB, loss=0.3931]\n",
      "Testing: 100%|██████████| 21/21 [04:58<00:00, 14.20s/it, loss=1.4152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, lr_rate 6.400000000000001e-05\n",
      "loss_train: 0.5010| loss_valid: 1.6823|\n",
      "metric 0.504115\n",
      "Elapsed time: 00:24:51\n",
      "---------------------epoch:8/15---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 42/81 [10:18<09:29, 14.60s/it, gpu_load=5.34GB, loss=0.5558]"
     ]
    }
   ],
   "source": [
    "# Проведем обучение модели. Для корректной работы и для защиты от сбоев будем сохранять модель после каждой эпохи\n",
    "for epoch_i in range(1, config.epochs + 1):\n",
    "    start = time.time()\n",
    "\n",
    "    print(f'---------------------epoch:{epoch_i}/{config.epochs}---------------------')\n",
    "\n",
    "    # loss\n",
    "    avg_train_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    summa = 0\n",
    "    ############## Train #############\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for X,y in (train_pbar):\n",
    "        X_batch = X.to(config.device)\n",
    "        y_batch = y.to(config.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        res = model.forward(X_batch)\n",
    "    \n",
    "        loss = loss_f(res, y_batch)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            train_pbar.set_postfix(gpu_load=f\"{torch.cuda.memory_allocated() / 1024 ** 3:.2f}GB\",\n",
    "                                   loss=f\"{loss.item():.4f}\")\n",
    "        else:\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_train_loss += loss * len(y_batch)\n",
    "\n",
    "        del X, res\n",
    "        \n",
    "\n",
    "    \n",
    "    ########## VALIDATION ###############\n",
    "    model.eval()\n",
    "    valid_pbar = tqdm(valid_loader, desc=\"Testing\")\n",
    "    with torch.no_grad():\n",
    "        for X,y in (valid_pbar):\n",
    "            X_batch = X.to(config.device)\n",
    "            y_batch = y.to(config.device)\n",
    "\n",
    "            res = model.forward(X_batch)\n",
    "            \n",
    "            loss = loss_f(res, y_batch)\n",
    "            avg_val_loss += loss * len(y_batch)\n",
    "            valid_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "            res = res.detach().cpu()\n",
    "            y_batch = y_batch.cpu()\n",
    "            \n",
    "            preds = torch.max(F.softmax(res, dim=1), dim=1)\n",
    "            correct= torch.eq(preds[1], y_batch)\n",
    "            summa += torch.sum(correct).item()\n",
    "\n",
    "            del X, res\n",
    "            \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    avg_train_loss = avg_train_loss / len(dataset_train)\n",
    "    avg_val_loss = avg_val_loss / len(dataset_test)\n",
    "    \n",
    "    acc = summa / len(dataset_test)\n",
    "\n",
    "    print(f'epoch: {epoch_i}, lr_rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "    print(\"loss_train: %0.4f| loss_valid: %0.4f|\" % (avg_train_loss, avg_val_loss))\n",
    "    print(f\"metric {acc:.<5g}\")\n",
    "\n",
    "    elapsed_time = time.time() - start\n",
    "    hours = int(elapsed_time // 3600)\n",
    "    minutes = int((elapsed_time % 3600) // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    print(f\"Elapsed time: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
    "    scheduler.step()\n",
    "    torch.save(model, f\"model_ep_{epoch_i}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наверное можно было бы обучить лучше, но у меня вылетел pycharm, и обучения я решил не перезапускать, т.к. слишом долго"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
