{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87de4e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Обучить модель на отдельных кадрах и провести сравнение'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Обучить модель на отдельных кадрах и провести сравнение\"\"\"\n",
    "\n",
    "# Начало блокнота до создания модели скопирую с блокнота 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2880c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт либ\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "\n",
    "from box import Box\n",
    "from tqdm import tqdm\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.io import read_video\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d2b7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name_video</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>videos/video_0000.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>videos/video_0001.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>videos/video_0002.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>videos/video_0003.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>videos/video_0004.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             name_video        label\n",
       "0           0  videos/video_0000.mp4  tap dancing\n",
       "1           1  videos/video_0001.mp4  tap dancing\n",
       "2           2  videos/video_0002.mp4  tap dancing\n",
       "3           3  videos/video_0003.mp4  tap dancing\n",
       "4           4  videos/video_0004.mp4  tap dancing"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на обновленную нашу дату \n",
    "df = pd.read_csv(\"../data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94c890c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name_video</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>videos/video_0000.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>videos/video_0001.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>videos/video_0002.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>videos/video_0003.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>videos/video_0004.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             name_video        label  target\n",
       "0           0  videos/video_0000.mp4  tap dancing       0\n",
       "1           1  videos/video_0001.mp4  tap dancing       0\n",
       "2           2  videos/video_0002.mp4  tap dancing       0\n",
       "3           3  videos/video_0003.mp4  tap dancing       0\n",
       "4           4  videos/video_0004.mp4  tap dancing       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Закодируем лейблы в числовые значения \n",
    "unique_labels = df['label'].unique()\n",
    "label_dict = {label: index for index, label in enumerate(unique_labels)}\n",
    "df['target'] = df.label.map(label_dict)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dce5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cоздадим конфиг для обучения модели\n",
    "config = Box()\n",
    "\n",
    "config.num_workers = 1\n",
    "config.batch_size = 24\n",
    "config.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config.seed = 1771\n",
    "config.model_name = 'tf_efficientnet_b0_ns'\n",
    "config.num_features = df.target.nunique()\n",
    "config.optimizer_lr = 0.001\n",
    "config.epochs = 20\n",
    "config.test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf71f3",
   "metadata": {},
   "source": [
    "Как как основная идея задания 2 заключается в обучения модели на отдельных кадрах, то мы будем рандомно дергать случайны кадр из видео, и обрабатывать его как изображение, пытаясь классифицировать действие, которое на нем происходит. То есть мы будем здесь классифицировать картинки - кадры из картинки. \n",
    "Для обучения модели возьмем известную сеть и быструю сеть tf_efficientnet_b0_ns - это улучшенная версия сети effnet_b0, обученная большем кол-ве данных и более мощной версии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a72dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменим наш датасет \n",
    "\n",
    "class DanceRndImgSet(Dataset):\n",
    "    def __init__(self, df, is_train = False):\n",
    "        self.df = df\n",
    "        self.video_path = \"..\"\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.aug =  A.Compose([\n",
    "                A.Resize(height=224, width=224, always_apply=True),\n",
    "                A.Rotate([-30,30], p=1),\n",
    "                A.CoarseDropout(max_height=int(224 * 0.17), max_width=int(224 * 0.17),\n",
    "                                 min_holes=4, max_holes=9, p=0.7),\n",
    "                A.GaussianBlur(blur_limit=(3, 7), p=0.05),\n",
    "                A.RandomSnow(p=0.05),\n",
    "                A.RandomRain(p=0.05),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "        else:\n",
    "            self.aug =  A.Compose([\n",
    "                A.Resize(height=224, width=224, always_apply=True),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        target = row['target']\n",
    "        \n",
    "        video_path = os.path.join(self.video_path, row['name_video'])\n",
    "\n",
    "        video, audio, info = read_video(video_path, pts_unit=\"sec\")\n",
    "        # Беру случайный кадр \n",
    "        if len(video) > 0:\n",
    "            total_frames = video.shape[0]\n",
    "            random_frame_index = torch.randint(0, total_frames, (1,)).item()\n",
    "            random_frame = video[random_frame_index].numpy()\n",
    "            frame_with_aug = self.aug(image=random_frame)['image']\n",
    "            \n",
    "        else:\n",
    "            random_frame = torch.randint(0, 256, (244, 244, 3), dtype=torch.uint8).numpy()\n",
    "            frame_with_aug = self.aug(image=random_frame)['image']\n",
    "            \n",
    "        label = torch.tensor(target).long()\n",
    "        return frame_with_aug, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b303938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем наши данные на тест и трейн. cоздадим тренеровочный и тестовый датасэт и даталоадэры\n",
    "train_df, val_df = train_test_split(df, \n",
    "                                    test_size=config.test_size,\n",
    "                                    random_state=config.seed,\n",
    "                                    stratify=df['target']\n",
    "                                   )\n",
    "dataset_train = DanceRndImgSet(train_df.reset_index(),\n",
    "                                 is_train=True)\n",
    "dataset_test = DanceRndImgSet(val_df.reset_index())\n",
    "\n",
    "train_loader = DataLoader(dataset_train,\n",
    "                          batch_size=config.batch_size,\n",
    "                          shuffle=True,\n",
    "#                          num_workers=config.num_workers\n",
    "                         )\n",
    "valid_loader = DataLoader(dataset_test,\n",
    "                          batch_size=config.batch_size,\n",
    "#                          num_workers=config.num_workers\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17749cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = config.model_name\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.classifier.in_features, config.epochs)\n",
    ")\n",
    "model.to(config.device)\n",
    "\n",
    "config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667c2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.optimizer_lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8729c5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------epoch:1/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:51<00:00,  2.11s/it, gpu_load=2.00GB, loss=2.0545]\n",
      "Testing: 100%|██████████| 21/21 [00:43<00:00,  2.08s/it, loss=2.4204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, lr_rate 0.001\n",
      "loss_train: 2.5715| loss_valid: 2.4394|\n",
      "metric 0.238683\n",
      "Elapsed time: 00:03:34\n",
      "---------------------epoch:2/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [03:02<00:00,  2.25s/it, gpu_load=2.00GB, loss=2.2720]\n",
      "Testing: 100%|██████████| 21/21 [00:42<00:00,  2.03s/it, loss=2.5425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, lr_rate 0.001\n",
      "loss_train: 2.3152| loss_valid: 2.3477|\n",
      "metric 0.238683\n",
      "Elapsed time: 00:03:44\n",
      "---------------------epoch:3/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:48<00:00,  2.08s/it, gpu_load=2.00GB, loss=1.6756]\n",
      "Testing: 100%|██████████| 21/21 [00:40<00:00,  1.95s/it, loss=2.1356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, lr_rate 0.001\n",
      "loss_train: 2.1620| loss_valid: 2.2660|\n",
      "metric 0.263374\n",
      "Elapsed time: 00:03:29\n",
      "---------------------epoch:4/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:51<00:00,  2.11s/it, gpu_load=2.00GB, loss=2.4227]\n",
      "Testing: 100%|██████████| 21/21 [00:41<00:00,  1.96s/it, loss=2.9795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, lr_rate 0.0008\n",
      "loss_train: 1.9605| loss_valid: 2.1919|\n",
      "metric 0.31893\n",
      "Elapsed time: 00:03:32\n",
      "---------------------epoch:5/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:51<00:00,  2.11s/it, gpu_load=2.00GB, loss=1.5113]\n",
      "Testing: 100%|██████████| 21/21 [00:41<00:00,  1.95s/it, loss=2.3763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, lr_rate 0.0008\n",
      "loss_train: 1.8707| loss_valid: 2.2770|\n",
      "metric 0.32716\n",
      "Elapsed time: 00:03:32\n",
      "---------------------epoch:6/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:49<00:00,  2.10s/it, gpu_load=2.00GB, loss=1.9566]\n",
      "Testing: 100%|██████████| 21/21 [00:41<00:00,  1.97s/it, loss=2.1417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, lr_rate 0.0008\n",
      "loss_train: 1.8133| loss_valid: 2.4097|\n",
      "metric 0.294239\n",
      "Elapsed time: 00:03:31\n",
      "---------------------epoch:7/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:49<00:00,  2.10s/it, gpu_load=2.00GB, loss=1.8554]\n",
      "Testing: 100%|██████████| 21/21 [00:41<00:00,  1.96s/it, loss=2.0411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, lr_rate 0.00064\n",
      "loss_train: 1.6744| loss_valid: 2.2558|\n",
      "metric 0.320988\n",
      "Elapsed time: 00:03:30\n",
      "---------------------epoch:8/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:52<00:00,  2.13s/it, gpu_load=2.00GB, loss=1.1476]\n",
      "Testing: 100%|██████████| 21/21 [00:42<00:00,  2.00s/it, loss=1.6063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, lr_rate 0.00064\n",
      "loss_train: 1.5373| loss_valid: 2.4207|\n",
      "metric 0.337449\n",
      "Elapsed time: 00:03:34\n",
      "---------------------epoch:9/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [03:00<00:00,  2.23s/it, gpu_load=2.00GB, loss=1.6136]\n",
      "Testing: 100%|██████████| 21/21 [00:44<00:00,  2.11s/it, loss=1.0565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, lr_rate 0.00064\n",
      "loss_train: 1.4162| loss_valid: 2.4112|\n",
      "metric 0.316872\n",
      "Elapsed time: 00:03:45\n",
      "---------------------epoch:10/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:49<00:00,  2.10s/it, gpu_load=2.00GB, loss=1.1814]\n",
      "Testing: 100%|██████████| 21/21 [00:41<00:00,  1.95s/it, loss=1.4449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, lr_rate 0.0005120000000000001\n",
      "loss_train: 1.2557| loss_valid: 2.4806|\n",
      "metric 0.345679\n",
      "Elapsed time: 00:03:30\n",
      "---------------------epoch:11/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:55<00:00,  2.17s/it, gpu_load=2.00GB, loss=1.1574]\n",
      "Testing: 100%|██████████| 21/21 [00:42<00:00,  2.04s/it, loss=1.7151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, lr_rate 0.0005120000000000001\n",
      "loss_train: 1.1568| loss_valid: 2.5710|\n",
      "metric 0.31893\n",
      "Elapsed time: 00:03:38\n",
      "---------------------epoch:12/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:51<00:00,  2.12s/it, gpu_load=2.00GB, loss=0.9832]\n",
      "Testing: 100%|██████████| 21/21 [00:42<00:00,  2.02s/it, loss=1.9996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, lr_rate 0.0005120000000000001\n",
      "loss_train: 1.0686| loss_valid: 2.6311|\n",
      "metric 0.316872\n",
      "Elapsed time: 00:03:33\n",
      "---------------------epoch:13/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:55<00:00,  2.17s/it, gpu_load=2.00GB, loss=1.3837]\n",
      "Testing: 100%|██████████| 21/21 [00:39<00:00,  1.89s/it, loss=1.5285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, lr_rate 0.0004096000000000001\n",
      "loss_train: 0.9860| loss_valid: 2.5562|\n",
      "metric 0.341564\n",
      "Elapsed time: 00:03:35\n",
      "---------------------epoch:14/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:56<00:00,  2.18s/it, gpu_load=2.00GB, loss=1.1017]\n",
      "Testing: 100%|██████████| 21/21 [00:42<00:00,  2.02s/it, loss=1.9806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, lr_rate 0.0004096000000000001\n",
      "loss_train: 0.8527| loss_valid: 2.7877|\n",
      "metric 0.316872\n",
      "Elapsed time: 00:03:39\n",
      "---------------------epoch:15/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:52<00:00,  2.13s/it, gpu_load=2.00GB, loss=0.7469]\n",
      "Testing: 100%|██████████| 21/21 [00:41<00:00,  1.99s/it, loss=1.8817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, lr_rate 0.0004096000000000001\n",
      "loss_train: 0.7964| loss_valid: 2.6725|\n",
      "metric 0.320988\n",
      "Elapsed time: 00:03:33\n",
      "---------------------epoch:16/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:46<00:00,  2.06s/it, gpu_load=2.00GB, loss=0.8067]\n",
      "Testing: 100%|██████████| 21/21 [00:39<00:00,  1.89s/it, loss=1.5677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, lr_rate 0.0003276800000000001\n",
      "loss_train: 0.7470| loss_valid: 2.8103|\n",
      "metric 0.345679\n",
      "Elapsed time: 00:03:26\n",
      "---------------------epoch:17/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:58<00:00,  2.20s/it, gpu_load=2.00GB, loss=0.3578]\n",
      "Testing: 100%|██████████| 21/21 [00:43<00:00,  2.09s/it, loss=2.5000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, lr_rate 0.0003276800000000001\n",
      "loss_train: 0.6188| loss_valid: 2.8459|\n",
      "metric 0.335391\n",
      "Elapsed time: 00:03:42\n",
      "---------------------epoch:18/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:49<00:00,  2.10s/it, gpu_load=2.00GB, loss=0.5374]\n",
      "Testing: 100%|██████████| 21/21 [00:40<00:00,  1.92s/it, loss=2.0449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, lr_rate 0.0003276800000000001\n",
      "loss_train: 0.6015| loss_valid: 2.9375|\n",
      "metric 0.320988\n",
      "Elapsed time: 00:03:30\n",
      "---------------------epoch:19/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:49<00:00,  2.09s/it, gpu_load=2.00GB, loss=0.2645]\n",
      "Testing: 100%|██████████| 21/21 [00:42<00:00,  2.02s/it, loss=2.7694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, lr_rate 0.0002621440000000001\n",
      "loss_train: 0.5543| loss_valid: 2.9600|\n",
      "metric 0.341564\n",
      "Elapsed time: 00:03:32\n",
      "---------------------epoch:20/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [02:52<00:00,  2.13s/it, gpu_load=2.00GB, loss=0.6243]\n",
      "Testing: 100%|██████████| 21/21 [00:48<00:00,  2.33s/it, loss=1.8829]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, lr_rate 0.0002621440000000001\n",
      "loss_train: 0.5373| loss_valid: 2.9396|\n",
      "metric 0.335391\n",
      "Elapsed time: 00:03:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Проведем обучение модели. Для корректной работы и для защиты от сбоев будем сохранять модель после каждой эпохи\n",
    "for epoch_i in range(1, config.epochs + 1):\n",
    "    start = time.time()\n",
    "\n",
    "    print(f'---------------------epoch:{epoch_i}/{config.epochs}---------------------')\n",
    "\n",
    "    # loss\n",
    "    avg_train_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    summa = 0\n",
    "    ############## Train #############\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for X,y in (train_pbar):\n",
    "        X_batch = X.to(config.device)\n",
    "        y_batch = y.to(config.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        res = model.forward(X_batch)\n",
    "    \n",
    "        loss = loss_f(res, y_batch)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            train_pbar.set_postfix(gpu_load=f\"{torch.cuda.memory_allocated() / 1024 ** 3:.2f}GB\",\n",
    "                                   loss=f\"{loss.item():.4f}\")\n",
    "        else:\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_train_loss += loss * len(y_batch)\n",
    "\n",
    "        del X, res\n",
    "        \n",
    "\n",
    "    \n",
    "    ########## VALIDATION ###############\n",
    "    model.eval()\n",
    "    valid_pbar = tqdm(valid_loader, desc=\"Testing\")\n",
    "    with torch.no_grad():\n",
    "        for X,y in (valid_pbar):\n",
    "            X_batch = X.to(config.device)\n",
    "            y_batch = y.to(config.device)\n",
    "\n",
    "            res = model.forward(X_batch)\n",
    "            \n",
    "            loss = loss_f(res, y_batch)\n",
    "            avg_val_loss += loss * len(y_batch)\n",
    "            valid_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "            res = res.detach().cpu()\n",
    "            y_batch = y_batch.cpu()\n",
    "            \n",
    "            preds = torch.max(F.softmax(res, dim=1), dim=1)\n",
    "            correct= torch.eq(preds[1], y_batch)\n",
    "            summa += torch.sum(correct).item()\n",
    "\n",
    "            del X, res\n",
    "            \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    avg_train_loss = avg_train_loss / len(dataset_train)\n",
    "    avg_val_loss = avg_val_loss / len(dataset_test)\n",
    "    \n",
    "    acc = summa / len(dataset_test)\n",
    "\n",
    "    print(f'epoch: {epoch_i}, lr_rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "    print(\"loss_train: %0.4f| loss_valid: %0.4f|\" % (avg_train_loss, avg_val_loss))\n",
    "    print(f\"metric {acc:.<5g}\")\n",
    "\n",
    "    elapsed_time = time.time() - start\n",
    "    hours = int(elapsed_time // 3600)\n",
    "    minutes = int((elapsed_time % 3600) // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    print(f\"Elapsed time: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
    "    scheduler.step()\n",
    "    torch.save(model, f\"model_ep_{epoch_i}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f63ecf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Как мы видем после 10ой эпохи модель начала расходиться. Дальше 10ой эпохи началось переобучение модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f4a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b37b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
