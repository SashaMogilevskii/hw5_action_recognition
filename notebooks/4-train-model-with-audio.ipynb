{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc77883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Обучить модель классификации видео с другим подходом и провести сравнение - 5 баллов'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Обучить модель классификации видео с другим подходом и провести сравнение - 5 баллов\"\"\"\n",
    "\n",
    "# Начало блокнота до создания модели скопирую с блокнота 2 и 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff8384",
   "metadata": {},
   "source": [
    "Каждое видео сопроваждается аудодорожкой. Возьмем аудорожки с каждого видео и попробуем предсказать label по аудидорожке. \n",
    "Будем брать аудиозаписи длиной 5 секунд на частоте 16кГц. Если у аудиозаписи длина меньше - будем брать случайный кроп. \n",
    "Если больше - будем добавлять паддинг этой же аудизаписью. Далее аудиозаписи будем переводить в изображенине (mel-spectogramm) и работать с ними как с изображениями. Таким образом каждая видеозапись будет конвенртированна в аудиозапись. \n",
    "Для данной задачи будем обучать сеть eff_net_b2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865b4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт либ\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import albumentations\n",
    "import albumentations as A\n",
    "\n",
    "from box import Box\n",
    "from tqdm import tqdm\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.io import read_video\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e3d7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name_video</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>videos/video_0000.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>videos/video_0001.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>videos/video_0002.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>videos/video_0003.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>videos/video_0004.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             name_video        label\n",
       "0           0  videos/video_0000.mp4  tap dancing\n",
       "1           1  videos/video_0001.mp4  tap dancing\n",
       "2           2  videos/video_0002.mp4  tap dancing\n",
       "3           3  videos/video_0003.mp4  tap dancing\n",
       "4           4  videos/video_0004.mp4  tap dancing"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на обновленную нашу дату \n",
    "df = pd.read_csv(\"../data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7712129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name_video</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>videos/video_0000.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>videos/video_0001.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>videos/video_0002.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>videos/video_0003.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>videos/video_0004.mp4</td>\n",
       "      <td>tap dancing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             name_video        label  target\n",
       "0           0  videos/video_0000.mp4  tap dancing       0\n",
       "1           1  videos/video_0001.mp4  tap dancing       0\n",
       "2           2  videos/video_0002.mp4  tap dancing       0\n",
       "3           3  videos/video_0003.mp4  tap dancing       0\n",
       "4           4  videos/video_0004.mp4  tap dancing       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Закодируем лейблы в числовые значения \n",
    "unique_labels = df['label'].unique()\n",
    "label_dict = {label: index for index, label in enumerate(unique_labels)}\n",
    "df['target'] = df.label.map(label_dict)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c8c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cоздадим конфиг для обучения модели\n",
    "config = Box()\n",
    "\n",
    "config.num_workers = 1\n",
    "config.batch_size = 24\n",
    "config.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config.seed = 1771\n",
    "config.model_name = 'tf_efficientnet_b2'\n",
    "config.num_features = df.target.nunique()\n",
    "config.optimizer_lr = 0.001\n",
    "config.epochs = 20\n",
    "config.test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd97e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_or_pad(y, length, start=None):\n",
    "    \"\"\"\n",
    "    Crop or padding for train audio\n",
    "    :param y:\n",
    "    :param length:\n",
    "    :param start:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, np.zeros(length - len(y))])\n",
    "        n_repeats = length // len(y)\n",
    "        epsilon = length % len(y)\n",
    "        y = np.concatenate([y] * n_repeats + [y[:epsilon]])\n",
    "\n",
    "    elif len(y) > length:\n",
    "        start = start or np.random.randint(len(y) - length)\n",
    "        y = y[start:start + length]\n",
    "\n",
    "    return y\n",
    "\n",
    "def compute_melspec(y, sr, n_mels, fmin, fmax, n_fft=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Computes a mel-spectrogram and puts it at decibel scale\n",
    "    Arguments:\n",
    "        y {np array} -- signal\n",
    "        params {AudioParams} -- Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n",
    "    Returns:\n",
    "        np array -- Mel-spectrogram\n",
    "    \"\"\"\n",
    "    if fmax is None:\n",
    "        fmax = sr // 2\n",
    "\n",
    "\n",
    "    melspec = lb.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_mels=n_mels, fmin=fmin, fmax=fmax, n_fft=n_fft, hop_length=hop_length\n",
    "    )\n",
    "\n",
    "    melspec = lb.power_to_db(melspec.astype(np.float32), ref=np.max)\n",
    "    return melspec\n",
    "\n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V\n",
    "\n",
    "def normalize(image):\n",
    "    # image = image.astype(\"float32\", copy=False) / 255.0\n",
    "    image = image.astype(np.uint8)\n",
    "    image = np.stack([image, image, image], axis=-1)\n",
    "    transform = albumentations.Compose([\n",
    "        albumentations.Normalize((0.485, 0.456, 0.406),\n",
    "                                 (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "    return transform(image=image)['image'].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709c3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменим наш датасет \n",
    "from moviepy.editor import VideoFileClip\n",
    "import librosa as lb\n",
    "from scipy.signal import resample\n",
    "\n",
    "class DanceAudioSet(Dataset):\n",
    "    def __init__(self, df, is_train = False):\n",
    "        self.df = df\n",
    "        self.video_path = \"..\"\n",
    "        self.is_train = is_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        target = row['target']\n",
    "        video_path = os.path.join(self.video_path, row['name_video'])\n",
    "        \n",
    "        # Считываем только аудиозапись. Все аудиодорожки частотой 44100. \n",
    "        target_sr = 44100\n",
    "        try:\n",
    "            video = VideoFileClip(video_path)\n",
    "            audio = video.audio\n",
    "            audio_array = audio.to_soundarray()\n",
    "            if audio_array.ndim > 1:\n",
    "                audio_mono = np.mean(audio_array, axis=1)\n",
    "            else:\n",
    "                audio_mono = audio_array\n",
    "\n",
    "            crop_audio = crop_or_pad(audio_mono, length=target_sr * 5)\n",
    "\n",
    "            melspec = compute_melspec(crop_audio,\n",
    "                                      sr=target_sr,\n",
    "                                      n_mels=128,\n",
    "                                      fmin=0,\n",
    "                                      fmax=target_sr // 2,\n",
    "                                      n_fft=2048,\n",
    "                                      hop_length=512)\n",
    "            image = mono_to_color(melspec)\n",
    "            image = normalize(image)\n",
    "            image = torch.tensor(image).float()\n",
    "        except:\n",
    "            image = torch.randint(0,1,(3, 431, 128))\n",
    "            \n",
    "        \n",
    "        label = torch.tensor(target).long()\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4197d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем наши данные на тест и трейн. cоздадим тренеровочный и тестовый датасэт и даталоадэры\n",
    "train_df, val_df = train_test_split(df, \n",
    "                                    test_size=config.test_size,\n",
    "                                    random_state=config.seed,\n",
    "                                    stratify=df['target']\n",
    "                                   )\n",
    "dataset_train = DanceAudioSet(train_df.reset_index(),\n",
    "                                 is_train=True)\n",
    "dataset_test = DanceAudioSet(val_df.reset_index())\n",
    "\n",
    "train_loader = DataLoader(dataset_train,\n",
    "                          batch_size=config.batch_size,\n",
    "                          shuffle=True,\n",
    "#                          num_workers=config.num_workers\n",
    "                         )\n",
    "valid_loader = DataLoader(dataset_test,\n",
    "                          batch_size=config.batch_size,\n",
    "#                          num_workers=config.num_workers\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b951ebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = config.model_name\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.classifier.in_features, config.epochs)\n",
    ")\n",
    "model.to(config.device)\n",
    "\n",
    "config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55c25ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.optimizer_lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5917667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------epoch:1/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [10:43<00:00,  7.95s/it, gpu_load=3.21GB, loss=2.3662]\n",
      "Testing: 100%|██████████| 21/21 [02:39<00:00,  7.61s/it, loss=2.0172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, lr_rate 0.001\n",
      "loss_train: 2.4141| loss_valid: 2.5576|\n",
      "metric 0.244856\n",
      "Elapsed time: 00:13:23\n",
      "---------------------epoch:2/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [11:00<00:00,  8.15s/it, gpu_load=3.21GB, loss=1.7755]\n",
      "Testing: 100%|██████████| 21/21 [02:52<00:00,  8.22s/it, loss=1.9081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, lr_rate 0.001\n",
      "loss_train: 2.0361| loss_valid: 2.2602|\n",
      "metric 0.323045\n",
      "Elapsed time: 00:13:53\n",
      "---------------------epoch:3/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [11:53<00:00,  8.81s/it, gpu_load=3.21GB, loss=1.9143]\n",
      "Testing: 100%|██████████| 21/21 [03:05<00:00,  8.84s/it, loss=1.8884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, lr_rate 0.001\n",
      "loss_train: 1.8171| loss_valid: 2.0315|\n",
      "metric 0.399177\n",
      "Elapsed time: 00:14:59\n",
      "---------------------epoch:4/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [11:53<00:00,  8.81s/it, gpu_load=3.21GB, loss=1.4358]\n",
      "Testing: 100%|██████████| 21/21 [02:46<00:00,  7.94s/it, loss=1.8757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, lr_rate 0.0008\n",
      "loss_train: 1.5516| loss_valid: 2.1806|\n",
      "metric 0.390947\n",
      "Elapsed time: 00:14:40\n",
      "---------------------epoch:5/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [10:41<00:00,  7.92s/it, gpu_load=3.21GB, loss=1.7663]\n",
      "Testing: 100%|██████████| 21/21 [02:32<00:00,  7.26s/it, loss=1.7021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, lr_rate 0.0008\n",
      "loss_train: 1.3342| loss_valid: 2.1246|\n",
      "metric 0.353909\n",
      "Elapsed time: 00:13:13\n",
      "---------------------epoch:6/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [11:32<00:00,  8.54s/it, gpu_load=3.21GB, loss=1.5640]\n",
      "Testing: 100%|██████████| 21/21 [02:57<00:00,  8.45s/it, loss=1.8947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, lr_rate 0.0008\n",
      "loss_train: 1.1703| loss_valid: 2.1359|\n",
      "metric 0.395062\n",
      "Elapsed time: 00:14:29\n",
      "---------------------epoch:7/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [11:24<00:00,  8.45s/it, gpu_load=3.21GB, loss=1.2133]\n",
      "Testing: 100%|██████████| 21/21 [02:56<00:00,  8.42s/it, loss=2.6311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, lr_rate 0.00064\n",
      "loss_train: 0.9020| loss_valid: 2.1918|\n",
      "metric 0.432099\n",
      "Elapsed time: 00:14:21\n",
      "---------------------epoch:8/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [12:11<00:00,  9.03s/it, gpu_load=3.21GB, loss=0.6375]\n",
      "Testing: 100%|██████████| 21/21 [02:42<00:00,  7.73s/it, loss=2.5433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, lr_rate 0.00064\n",
      "loss_train: 0.7078| loss_valid: 2.3737|\n",
      "metric 0.390947\n",
      "Elapsed time: 00:14:54\n",
      "---------------------epoch:9/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [11:30<00:00,  8.52s/it, gpu_load=3.21GB, loss=1.0601]\n",
      "Testing: 100%|██████████| 21/21 [03:10<00:00,  9.07s/it, loss=3.1093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, lr_rate 0.00064\n",
      "loss_train: 0.5995| loss_valid: 2.6258|\n",
      "metric 0.390947\n",
      "Elapsed time: 00:14:40\n",
      "---------------------epoch:10/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [10:56<00:00,  8.10s/it, gpu_load=3.21GB, loss=0.5065]\n",
      "Testing: 100%|██████████| 21/21 [02:33<00:00,  7.32s/it, loss=2.3375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, lr_rate 0.0005120000000000001\n",
      "loss_train: 0.4350| loss_valid: 2.5636|\n",
      "metric 0.425926\n",
      "Elapsed time: 00:13:30\n",
      "---------------------epoch:11/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [10:35<00:00,  7.85s/it, gpu_load=3.21GB, loss=0.5840]\n",
      "Testing: 100%|██████████| 21/21 [02:29<00:00,  7.12s/it, loss=2.4233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, lr_rate 0.0005120000000000001\n",
      "loss_train: 0.3721| loss_valid: 2.6240|\n",
      "metric 0.41358\n",
      "Elapsed time: 00:13:05\n",
      "---------------------epoch:12/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [09:53<00:00,  7.32s/it, gpu_load=3.21GB, loss=0.0979]\n",
      "Testing: 100%|██████████| 21/21 [02:28<00:00,  7.05s/it, loss=3.5517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, lr_rate 0.0005120000000000001\n",
      "loss_train: 0.3004| loss_valid: 2.6800|\n",
      "metric 0.397119\n",
      "Elapsed time: 00:12:21\n",
      "---------------------epoch:13/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [10:02<00:00,  7.44s/it, gpu_load=3.21GB, loss=0.3730]\n",
      "Testing: 100%|██████████| 21/21 [02:27<00:00,  7.01s/it, loss=3.3222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, lr_rate 0.0004096000000000001\n",
      "loss_train: 0.2460| loss_valid: 2.4993|\n",
      "metric 0.432099\n",
      "Elapsed time: 00:12:30\n",
      "---------------------epoch:14/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [09:53<00:00,  7.32s/it, gpu_load=3.21GB, loss=0.0511]\n",
      "Testing: 100%|██████████| 21/21 [02:27<00:00,  7.04s/it, loss=3.1269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, lr_rate 0.0004096000000000001\n",
      "loss_train: 0.2182| loss_valid: 2.6179|\n",
      "metric 0.41358\n",
      "Elapsed time: 00:12:21\n",
      "---------------------epoch:15/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [09:53<00:00,  7.33s/it, gpu_load=3.21GB, loss=0.1508]\n",
      "Testing: 100%|██████████| 21/21 [02:28<00:00,  7.05s/it, loss=4.1746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, lr_rate 0.0004096000000000001\n",
      "loss_train: 0.1501| loss_valid: 3.0075|\n",
      "metric 0.399177\n",
      "Elapsed time: 00:12:21\n",
      "---------------------epoch:16/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [09:56<00:00,  7.36s/it, gpu_load=3.21GB, loss=0.3076]\n",
      "Testing: 100%|██████████| 21/21 [02:31<00:00,  7.24s/it, loss=3.7400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, lr_rate 0.0003276800000000001\n",
      "loss_train: 0.1623| loss_valid: 2.6402|\n",
      "metric 0.438272\n",
      "Elapsed time: 00:12:28\n",
      "---------------------epoch:17/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [09:59<00:00,  7.40s/it, gpu_load=3.21GB, loss=0.4786]\n",
      "Testing: 100%|██████████| 21/21 [02:32<00:00,  7.25s/it, loss=5.1536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, lr_rate 0.0003276800000000001\n",
      "loss_train: 0.1331| loss_valid: 2.6773|\n",
      "metric 0.444444\n",
      "Elapsed time: 00:12:31\n",
      "---------------------epoch:18/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [10:00<00:00,  7.41s/it, gpu_load=3.21GB, loss=0.0939]\n",
      "Testing: 100%|██████████| 21/21 [02:28<00:00,  7.07s/it, loss=5.6931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, lr_rate 0.0003276800000000001\n",
      "loss_train: 0.1214| loss_valid: 2.8313|\n",
      "metric 0.432099\n",
      "Elapsed time: 00:12:28\n",
      "---------------------epoch:19/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [10:00<00:00,  7.41s/it, gpu_load=3.21GB, loss=0.1203]\n",
      "Testing: 100%|██████████| 21/21 [02:29<00:00,  7.10s/it, loss=2.9988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, lr_rate 0.0002621440000000001\n",
      "loss_train: 0.0974| loss_valid: 2.7730|\n",
      "metric 0.440329\n",
      "Elapsed time: 00:12:29\n",
      "---------------------epoch:20/20---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 81/81 [10:00<00:00,  7.41s/it, gpu_load=3.21GB, loss=0.0338]\n",
      "Testing: 100%|██████████| 21/21 [02:30<00:00,  7.16s/it, loss=3.1414]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, lr_rate 0.0002621440000000001\n",
      "loss_train: 0.0760| loss_valid: 2.8291|\n",
      "metric 0.45679\n",
      "Elapsed time: 00:12:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Проведем обучение модели. Для корректной работы и для защиты от сбоев будем сохранять модель после каждой эпохи\n",
    "for epoch_i in range(1, config.epochs + 1):\n",
    "    start = time.time()\n",
    "\n",
    "    print(f'---------------------epoch:{epoch_i}/{config.epochs}---------------------')\n",
    "\n",
    "    # loss\n",
    "    avg_train_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    summa = 0\n",
    "    ############## Train #############\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for X,y in (train_pbar):\n",
    "        X_batch = X.to(config.device)\n",
    "        y_batch = y.to(config.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        res = model.forward(X_batch)\n",
    "    \n",
    "        loss = loss_f(res, y_batch)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            train_pbar.set_postfix(gpu_load=f\"{torch.cuda.memory_allocated() / 1024 ** 3:.2f}GB\",\n",
    "                                   loss=f\"{loss.item():.4f}\")\n",
    "        else:\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_train_loss += loss * len(y_batch)\n",
    "\n",
    "        del X, res\n",
    "        \n",
    "\n",
    "    \n",
    "    ########## VALIDATION ###############\n",
    "    model.eval()\n",
    "    valid_pbar = tqdm(valid_loader, desc=\"Testing\")\n",
    "    with torch.no_grad():\n",
    "        for X,y in (valid_pbar):\n",
    "            X_batch = X.to(config.device)\n",
    "            y_batch = y.to(config.device)\n",
    "\n",
    "            res = model.forward(X_batch)\n",
    "            \n",
    "            loss = loss_f(res, y_batch)\n",
    "            avg_val_loss += loss * len(y_batch)\n",
    "            valid_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "            res = res.detach().cpu()\n",
    "            y_batch = y_batch.cpu()\n",
    "            \n",
    "            preds = torch.max(F.softmax(res, dim=1), dim=1)\n",
    "            correct= torch.eq(preds[1], y_batch)\n",
    "            summa += torch.sum(correct).item()\n",
    "\n",
    "            del X, res\n",
    "            \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    avg_train_loss = avg_train_loss / len(dataset_train)\n",
    "    avg_val_loss = avg_val_loss / len(dataset_test)\n",
    "    \n",
    "    acc = summa / len(dataset_test)\n",
    "\n",
    "    print(f'epoch: {epoch_i}, lr_rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "    print(\"loss_train: %0.4f| loss_valid: %0.4f|\" % (avg_train_loss, avg_val_loss))\n",
    "    print(f\"metric {acc:.<5g}\")\n",
    "\n",
    "    elapsed_time = time.time() - start\n",
    "    hours = int(elapsed_time // 3600)\n",
    "    minutes = int((elapsed_time % 3600) // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    print(f\"Elapsed time: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
    "    scheduler.step()\n",
    "    torch.save(model, f\"model_ep_{epoch_i}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14332ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Как мы видим наилучшей результат был получен только на 20ой эпохе. Возможно, если бы мы поставили на эпох 50-60 то результаты были бы еще лучше. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
